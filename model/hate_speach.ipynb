{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Om45omgBBvhu"
   },
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "MoLWixFmCaLt",
    "outputId": "83b81f52-9848-443a-a507-a0ef4e2c537b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cowok usaha lacak perhati gue lantas remeh per...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt guna guna telat tau edan sarap gue gaul cig...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41 kadang pikir percaya tuhan jatuh kali kali ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>guna guna ku tau mata sipit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>guna guna kaum cebong kafir dongok dungu haha</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  HS  Abusive\n",
       "0           0  cowok usaha lacak perhati gue lantas remeh per...   1        1\n",
       "1           1  rt guna guna telat tau edan sarap gue gaul cig...   0        1\n",
       "2           2  41 kadang pikir percaya tuhan jatuh kali kali ...   0        0\n",
       "3           3                        guna guna ku tau mata sipit   0        0\n",
       "4           4      guna guna kaum cebong kafir dongok dungu haha   1        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "cENi54MAC0qF",
    "outputId": "520bca57-c169-4dd0-d929-e479eab28caf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.tiopan\\AppData\\Local\\Temp\\ipykernel_9196\\1010250552.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Tweet'] = df['Tweet'].str.replace('http\\S+|www.\\S+', '', case=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cowok usaha lacak perhati gue lantas remeh per...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt guna guna telat tau edan sarap gue gaul cig...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41 kadang pikir percaya tuhan jatuh kali kali ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>guna guna ku tau mata sipit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>guna guna kaum cebong kafir dongok dungu haha</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  HS  Abusive\n",
       "0           0  cowok usaha lacak perhati gue lantas remeh per...   1        1\n",
       "1           1  rt guna guna telat tau edan sarap gue gaul cig...   0        1\n",
       "2           2  41 kadang pikir percaya tuhan jatuh kali kali ...   0        0\n",
       "3           3                        guna guna ku tau mata sipit   0        0\n",
       "4           4      guna guna kaum cebong kafir dongok dungu haha   1        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menghilangkan URL pada dataset dengan kolom 'text'\n",
    "df['Tweet'] = df['Tweet'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.tiopan\\AppData\\Local\\Temp\\ipykernel_9196\\3060063186.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed_text = pd.DataFrame(processed_text)[0].str.replace('http\\S+|www.\\S+', '', case=False)\n",
      "C:\\Users\\alexander.tiopan\\AppData\\Local\\Temp\\ipykernel_9196\\3060063186.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed_text = processed_text.str.replace('@[^\\s]+','', case=False)\n",
      "C:\\Users\\alexander.tiopan\\AppData\\Local\\Temp\\ipykernel_9196\\3060063186.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed_text = processed_text.str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_number(text):\n",
    "    return re.sub(\"[^a-zA-Z]\", \" \",str(text))\n",
    "\n",
    "processed_text = ['gak jelas deh %343434']\n",
    "processed_text = pd.DataFrame(processed_text)[0].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "processed_text = processed_text.str.replace('@[^\\s]+','', case=False)\n",
    "processed_text = processed_text.str.replace('[^\\w\\s]','')\n",
    "processed_text = processed_text.apply(remove_number)\n",
    "processed_text = processed_text.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "processed_text = processed_text.apply(identify_tokens)\n",
    "processed_text = processed_text.apply(stop_list)\n",
    "processed_text = processed_text.apply(stem_list)\n",
    "input_payloads = \" \".join(processed_text[0])\n",
    "\n",
    "input_payloads = vectorizer.transform([input_payloads])\n",
    "predictions = svm.predict(input_payloads)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "W4CNerBDDDMR",
    "outputId": "58414e3e-adaf-41c7-f517-4606c5f38629"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.tiopan\\AppData\\Local\\Temp\\ipykernel_9196\\1426673619.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Tweet'] = df['Tweet'].str.replace('@[^\\s]+','', case=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cowok usaha lacak perhati gue lantas remeh per...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt guna guna telat tau edan sarap gue gaul cig...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41 kadang pikir percaya tuhan jatuh kali kali ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>guna guna ku tau mata sipit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>guna guna kaum cebong kafir dongok dungu haha</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  HS  Abusive\n",
       "0           0  cowok usaha lacak perhati gue lantas remeh per...   1        1\n",
       "1           1  rt guna guna telat tau edan sarap gue gaul cig...   0        1\n",
       "2           2  41 kadang pikir percaya tuhan jatuh kali kali ...   0        0\n",
       "3           3                        guna guna ku tau mata sipit   0        0\n",
       "4           4      guna guna kaum cebong kafir dongok dungu haha   1        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menghilangkan kata yang diawali oleh simbol @ pada kolom 'text'\n",
    "df['Tweet'] = df['Tweet'].str.replace('@[^\\s]+','', case=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "h4diOx9eDxan",
    "outputId": "8fad1040-c166-4b44-f29c-e81a43204ac7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.tiopan\\AppData\\Local\\Temp\\ipykernel_9196\\3399026850.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Tweet'] = df['Tweet'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cowok usaha lacak perhati gue lantas remeh per...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt guna guna telat tau edan sarap gue gaul cig...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41 kadang pikir percaya tuhan jatuh kali kali ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>guna guna ku tau mata sipit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>guna guna kaum cebong kafir dongok dungu haha</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  HS  Abusive\n",
       "0           0  cowok usaha lacak perhati gue lantas remeh per...   1        1\n",
       "1           1  rt guna guna telat tau edan sarap gue gaul cig...   0        1\n",
       "2           2  41 kadang pikir percaya tuhan jatuh kali kali ...   0        0\n",
       "3           3                        guna guna ku tau mata sipit   0        0\n",
       "4           4      guna guna kaum cebong kafir dongok dungu haha   1        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#menghapus karakter selain huruf \n",
    "df['Tweet'] = df['Tweet'].str.replace('[^\\w\\s]','')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "L62NPEiiEUg1",
    "outputId": "0a290628-144a-4fb2-b4d7-c37d55767f03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cowok usaha lacak perhati gue lantas remeh per...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt guna guna telat tau edan sarap gue gaul cig...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>kadang pikir percaya tuhan jatuh kali kali ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>guna guna ku tau mata sipit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>guna guna kaum cebong kafir dongok dungu haha</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13164</th>\n",
       "      <td>13164</td>\n",
       "      <td>guna bicara ndasmu congor sekata anjing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13165</th>\n",
       "      <td>13165</td>\n",
       "      <td>guna kasur enak kunyuk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13166</th>\n",
       "      <td>13166</td>\n",
       "      <td>guna hati hati bisu bosan duh x</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13167</th>\n",
       "      <td>13167</td>\n",
       "      <td>guna guna guna guna bom real mudah deteksi bom...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13168</th>\n",
       "      <td>13168</td>\n",
       "      <td>guna situ foto ya kutil onta</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13169 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              Tweet  HS  \\\n",
       "0               0  cowok usaha lacak perhati gue lantas remeh per...   1   \n",
       "1               1  rt guna guna telat tau edan sarap gue gaul cig...   0   \n",
       "2               2     kadang pikir percaya tuhan jatuh kali kali ...   0   \n",
       "3               3                        guna guna ku tau mata sipit   0   \n",
       "4               4      guna guna kaum cebong kafir dongok dungu haha   1   \n",
       "...           ...                                                ...  ..   \n",
       "13164       13164            guna bicara ndasmu congor sekata anjing   1   \n",
       "13165       13165                             guna kasur enak kunyuk   0   \n",
       "13166       13166                  guna hati hati bisu bosan duh x     0   \n",
       "13167       13167  guna guna guna guna bom real mudah deteksi bom...   0   \n",
       "13168       13168                       guna situ foto ya kutil onta   1   \n",
       "\n",
       "       Abusive  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            1  \n",
       "...        ...  \n",
       "13164        1  \n",
       "13165        1  \n",
       "13166        0  \n",
       "13167        0  \n",
       "13168        1  \n",
       "\n",
       "[13169 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_number(text):\n",
    "    return re.sub(\"[^a-zA-Z]\", \" \",str(text))\n",
    "\n",
    "\n",
    "df['Tweet'] = df['Tweet'].apply(remove_number)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-xxTWmR_E8xa"
   },
   "outputs": [],
   "source": [
    "#case folding berupa lower case\n",
    "df['Tweet'] = df['Tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "eppLfL6EMVb4",
    "outputId": "9d230d8a-42f8-4cd8-b508-e9773bad5cbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.tiopan\\AppData\\Local\\Temp\\ipykernel_9196\\3069443452.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tweet'].iloc[i]=text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cowok usaha lacak perhati saya lantas remeh pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt berguna berguna telat tahu edan sarap saya ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>kadang pikir percaya tuhan jatuh kali kali kad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>berguna berguna saya tahu mata sipit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>berguna berguna kaum cebong kafir dungu dungu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>berguna ya bani taplak kawan kawan sangat sang...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>deklarasi pilih kepala daerah aman anti hoaks ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>saya selesai re watch aldnoah zero kampret kar...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>admin belanja port baik nak makan ais kepal mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>berguna enak ngewe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  HS  Abusive\n",
       "0           0  cowok usaha lacak perhati saya lantas remeh pe...   1        1\n",
       "1           1  rt berguna berguna telat tahu edan sarap saya ...   0        1\n",
       "2           2  kadang pikir percaya tuhan jatuh kali kali kad...   0        0\n",
       "3           3               berguna berguna saya tahu mata sipit   0        0\n",
       "4           4  berguna berguna kaum cebong kafir dungu dungu ...   1        1\n",
       "5           5  berguna ya bani taplak kawan kawan sangat sang...   1        1\n",
       "6           6  deklarasi pilih kepala daerah aman anti hoaks ...   0        0\n",
       "7           7  saya selesai re watch aldnoah zero kampret kar...   0        1\n",
       "8           8  admin belanja port baik nak makan ais kepal mi...   0        0\n",
       "9           9                                 berguna enak ngewe   0        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "\n",
    "reader = csv.reader(open('normalisasi.csv', 'r'))\n",
    "d = {}\n",
    "for row in reader:\n",
    "    k,v= row\n",
    "    d[k] = v\n",
    "    #print d[k]\n",
    "pat = re.compile(r\"\\b(%s)\\b\" % \"|\".join(d))\n",
    "for i in range(len(df)):\n",
    "    text = df['Tweet'].iloc[i]\n",
    "    text = pat.sub(lambda m: d.get(m.group()), text)\n",
    "    #print text\n",
    "    df['Tweet'].iloc[i]=text\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXK2QBVMFVXb",
    "outputId": "66a07f6f-7e75-4e16-b240-97e0f981417e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alexander.tiopan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Library\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhYwRspqFY8B",
    "outputId": "37d3d044-4508-40f8-9e6e-27db47720578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cowok', 'usaha', 'lacak', 'perhati', 'saya', 'lantas', 'remeh', 'perhati', 'saya', 'kasih', 'khusus', 'basic', 'cowok', 'bego']\n"
     ]
    }
   ],
   "source": [
    "# Menguji fungsi Tokenize\n",
    "example_text = df.iloc[0]\n",
    "print(nltk.word_tokenize(example_text['Tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lfyte8EsFeKb",
    "outputId": "d16e8fef-f721-4b74-fc62-964e5f5022ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [cowok, usaha, lacak, perhati, saya, lantas, r...\n",
       "1    [rt, berguna, berguna, telat, tahu, edan, sara...\n",
       "2    [kadang, pikir, percaya, tuhan, jatuh, kali, k...\n",
       "3          [berguna, berguna, saya, tahu, mata, sipit]\n",
       "4    [berguna, berguna, kaum, cebong, kafir, dungu,...\n",
       "Name: token, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menerapkan fungsi Tokenize pada Dataset\n",
    "def identify_tokens(row):\n",
    "    text = row\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # taken only words (not punctuation)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words\n",
    "\n",
    "df['token'] = df['Tweet'].apply(identify_tokens)\n",
    "df['token'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mpe3oJk7XOTH",
    "outputId": "745b30ed-c7fa-4bb5-ace3-0c1426ffecf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sastrawi\n",
      "  Using cached Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
      "Installing collected packages: sastrawi\n",
      "Successfully installed sastrawi-1.0.1\n",
      "['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua', 'ia', 'seperti', 'jika', 'jika', 'sehingga', 'kembali', 'dan', 'tidak', 'ini', 'karena', 'kepada', 'oleh', 'saat', 'harus', 'sementara', 'setelah', 'belum', 'kami', 'sekitar', 'bagi', 'serta', 'di', 'dari', 'telah', 'sebagai', 'masih', 'hal', 'ketika', 'adalah', 'itu', 'dalam', 'bisa', 'bahwa', 'atau', 'hanya', 'kita', 'dengan', 'akan', 'juga', 'ada', 'mereka', 'sudah', 'saya', 'terhadap', 'secara', 'agar', 'lain', 'anda', 'begitu', 'mengapa', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'sebelum', 'sesudah', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi', 'sementara', 'tetapi', 'apakah', 'kecuali', 'sebab', 'selain', 'seolah', 'seraya', 'seterusnya', 'tanpa', 'agak', 'boleh', 'dapat', 'dsb', 'dst', 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'tapi', 'ingin', 'juga', 'nggak', 'mari', 'nanti', 'melainkan', 'oh', 'ok', 'seharusnya', 'sebetulnya', 'setiap', 'setidaknya', 'sesuatu', 'pasti', 'saja', 'toh', 'ya', 'walau', 'tolong', 'tentu', 'amat', 'apalagi', 'bagaimanapun']\n"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "! pip install sastrawi\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "# Menerapkan stopwords bahasa Indonesia\n",
    "# stops = set(nltk.corpus.stopwords.words('indonesian'))\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "data_stopword = stop_stfactory.get_stop_words()\n",
    "stopword = stop_factory.create_stop_word_remover()\n",
    "print(data_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "t5yFipPgXYfR"
   },
   "outputs": [],
   "source": [
    "# Menerapkan fungsi Stopword pada Dataset, dan membuat kolom stopwords\n",
    "def stop_list(row):\n",
    "    my_list = row\n",
    "    stop_list = [stopword.remove(i) for i in my_list]\n",
    "    return (stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5R78BmTXe_Z",
    "outputId": "1ea40b5d-71bc-46ea-f178-c110568ea213"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [cowok, usaha, lacak, perhati, , lantas, remeh...\n",
       "1    [rt, berguna, berguna, telat, tahu, edan, sara...\n",
       "2    [kadang, pikir, percaya, tuhan, jatuh, kali, k...\n",
       "3              [berguna, berguna, , tahu, mata, sipit]\n",
       "4    [berguna, berguna, kaum, cebong, kafir, dungu,...\n",
       "Name: stop_words, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stop_words'] = df['token'].apply(stop_list)\n",
    "df['stop_words'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6-5tM8iXtaJ",
    "outputId": "18ae775c-632d-46b4-f2eb-1b8e9c39d08b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['penuh', 'barang', 'buka']\n"
     ]
    }
   ],
   "source": [
    "# Menguji fungsi StemmerFactory\n",
    "stemming = StemmerFactory().create_stemmer()\n",
    "my_list = ['memenuhi', 'barangnya', 'dibuka']\n",
    "print ([stemming.stem(i) for i in my_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "CcVLT2F2Xu7m",
    "outputId": "6cb880dd-4b97-41f3-9159-dc1d1f85538a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>token</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>stemmed_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cowok usaha lacak perhati saya lantas remeh pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[cowok, usaha, lacak, perhati, saya, lantas, r...</td>\n",
       "      <td>[cowok, usaha, lacak, perhati, , lantas, remeh...</td>\n",
       "      <td>[cowok, usaha, lacak, perhati, , lantas, remeh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt berguna berguna telat tahu edan sarap saya ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, berguna, berguna, telat, tahu, edan, sara...</td>\n",
       "      <td>[rt, berguna, berguna, telat, tahu, edan, sara...</td>\n",
       "      <td>[rt, guna, guna, telat, tahu, edan, sarap, , g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>kadang pikir percaya tuhan jatuh kali kali kad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[kadang, pikir, percaya, tuhan, jatuh, kali, k...</td>\n",
       "      <td>[kadang, pikir, percaya, tuhan, jatuh, kali, k...</td>\n",
       "      <td>[kadang, pikir, percaya, tuhan, jatuh, kali, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>berguna berguna saya tahu mata sipit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[berguna, berguna, saya, tahu, mata, sipit]</td>\n",
       "      <td>[berguna, berguna, , tahu, mata, sipit]</td>\n",
       "      <td>[guna, guna, , tahu, mata, sipit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>berguna berguna kaum cebong kafir dungu dungu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[berguna, berguna, kaum, cebong, kafir, dungu,...</td>\n",
       "      <td>[berguna, berguna, kaum, cebong, kafir, dungu,...</td>\n",
       "      <td>[guna, guna, kaum, cebong, kafir, dungu, dungu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  HS  Abusive  \\\n",
       "0           0  cowok usaha lacak perhati saya lantas remeh pe...   1        1   \n",
       "1           1  rt berguna berguna telat tahu edan sarap saya ...   0        1   \n",
       "2           2  kadang pikir percaya tuhan jatuh kali kali kad...   0        0   \n",
       "3           3               berguna berguna saya tahu mata sipit   0        0   \n",
       "4           4  berguna berguna kaum cebong kafir dungu dungu ...   1        1   \n",
       "\n",
       "                                               token  \\\n",
       "0  [cowok, usaha, lacak, perhati, saya, lantas, r...   \n",
       "1  [rt, berguna, berguna, telat, tahu, edan, sara...   \n",
       "2  [kadang, pikir, percaya, tuhan, jatuh, kali, k...   \n",
       "3        [berguna, berguna, saya, tahu, mata, sipit]   \n",
       "4  [berguna, berguna, kaum, cebong, kafir, dungu,...   \n",
       "\n",
       "                                          stop_words  \\\n",
       "0  [cowok, usaha, lacak, perhati, , lantas, remeh...   \n",
       "1  [rt, berguna, berguna, telat, tahu, edan, sara...   \n",
       "2  [kadang, pikir, percaya, tuhan, jatuh, kali, k...   \n",
       "3            [berguna, berguna, , tahu, mata, sipit]   \n",
       "4  [berguna, berguna, kaum, cebong, kafir, dungu,...   \n",
       "\n",
       "                                       stemmed_words  \n",
       "0  [cowok, usaha, lacak, perhati, , lantas, remeh...  \n",
       "1  [rt, guna, guna, telat, tahu, edan, sarap, , g...  \n",
       "2  [kadang, pikir, percaya, tuhan, jatuh, kali, k...  \n",
       "3                  [guna, guna, , tahu, mata, sipit]  \n",
       "4  [guna, guna, kaum, cebong, kafir, dungu, dungu...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menerapkan fungsi StemmerFactory pada Dataset, dan membuat kolom stemmed_words\n",
    "def stem_list(row):\n",
    "    my_list = row\n",
    "    stemmed_list = [stemming.stem(i) for i in my_list]\n",
    "    return (stemmed_list)\n",
    "\n",
    "df['stemmed_words'] = df['stop_words'].apply(stem_list)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "hBF-FeBrYiIN",
    "outputId": "50a1ee3a-8355-4a56-84ef-dd8d28306bed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>token</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>stemmed_words</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cowok usaha lacak perhati saya lantas remeh pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[cowok, usaha, lacak, perhati, saya, lantas, r...</td>\n",
       "      <td>[cowok, usaha, lacak, perhati, , lantas, remeh...</td>\n",
       "      <td>[cowok, usaha, lacak, perhati, , lantas, remeh...</td>\n",
       "      <td>cowok usaha lacak perhati  lantas remeh perhat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt berguna berguna telat tahu edan sarap saya ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, berguna, berguna, telat, tahu, edan, sara...</td>\n",
       "      <td>[rt, berguna, berguna, telat, tahu, edan, sara...</td>\n",
       "      <td>[rt, guna, guna, telat, tahu, edan, sarap, , g...</td>\n",
       "      <td>rt guna guna telat tahu edan sarap  gaul cigax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>kadang pikir percaya tuhan jatuh kali kali kad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[kadang, pikir, percaya, tuhan, jatuh, kali, k...</td>\n",
       "      <td>[kadang, pikir, percaya, tuhan, jatuh, kali, k...</td>\n",
       "      <td>[kadang, pikir, percaya, tuhan, jatuh, kali, k...</td>\n",
       "      <td>kadang pikir percaya tuhan jatuh kali kali kad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>berguna berguna saya tahu mata sipit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[berguna, berguna, saya, tahu, mata, sipit]</td>\n",
       "      <td>[berguna, berguna, , tahu, mata, sipit]</td>\n",
       "      <td>[guna, guna, , tahu, mata, sipit]</td>\n",
       "      <td>guna guna  tahu mata sipit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>berguna berguna kaum cebong kafir dungu dungu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[berguna, berguna, kaum, cebong, kafir, dungu,...</td>\n",
       "      <td>[berguna, berguna, kaum, cebong, kafir, dungu,...</td>\n",
       "      <td>[guna, guna, kaum, cebong, kafir, dungu, dungu...</td>\n",
       "      <td>guna guna kaum cebong kafir dungu dungu haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>berguna ya bani taplak kawan kawan sangat sang...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[berguna, ya, bani, taplak, kawan, kawan, sang...</td>\n",
       "      <td>[berguna, , bani, taplak, kawan, kawan, sangat...</td>\n",
       "      <td>[guna, , bani, taplak, kawan, kawan, sangat, s...</td>\n",
       "      <td>guna  bani taplak kawan kawan sangat sangat sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>deklarasi pilih kepala daerah aman anti hoaks ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[deklarasi, pilih, kepala, daerah, aman, anti,...</td>\n",
       "      <td>[deklarasi, pilih, kepala, daerah, aman, anti,...</td>\n",
       "      <td>[deklarasi, pilih, kepala, daerah, aman, anti,...</td>\n",
       "      <td>deklarasi pilih kepala daerah aman anti hoaks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>saya selesai re watch aldnoah zero kampret kar...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[saya, selesai, re, watch, aldnoah, zero, kamp...</td>\n",
       "      <td>[, selesai, re, watch, aldnoah, zero, kampret,...</td>\n",
       "      <td>[, selesai, re, watch, aldnoah, zero, kampret,...</td>\n",
       "      <td>selesai re watch aldnoah zero kampret karakte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>admin belanja port baik nak makan ais kepal mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[admin, belanja, port, baik, nak, makan, ais, ...</td>\n",
       "      <td>[admin, belanja, port, baik, nak, makan, ais, ...</td>\n",
       "      <td>[admin, belanja, port, baik, nak, makan, ais, ...</td>\n",
       "      <td>admin belanja port baik nak makan ais kepal mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>berguna enak ngewe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[berguna, enak, ngewe]</td>\n",
       "      <td>[berguna, enak, ngewe]</td>\n",
       "      <td>[guna, enak, ngewe]</td>\n",
       "      <td>guna enak ngewe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  HS  Abusive  \\\n",
       "0           0  cowok usaha lacak perhati saya lantas remeh pe...   1        1   \n",
       "1           1  rt berguna berguna telat tahu edan sarap saya ...   0        1   \n",
       "2           2  kadang pikir percaya tuhan jatuh kali kali kad...   0        0   \n",
       "3           3               berguna berguna saya tahu mata sipit   0        0   \n",
       "4           4  berguna berguna kaum cebong kafir dungu dungu ...   1        1   \n",
       "5           5  berguna ya bani taplak kawan kawan sangat sang...   1        1   \n",
       "6           6  deklarasi pilih kepala daerah aman anti hoaks ...   0        0   \n",
       "7           7  saya selesai re watch aldnoah zero kampret kar...   0        1   \n",
       "8           8  admin belanja port baik nak makan ais kepal mi...   0        0   \n",
       "9           9                                 berguna enak ngewe   0        1   \n",
       "\n",
       "                                               token  \\\n",
       "0  [cowok, usaha, lacak, perhati, saya, lantas, r...   \n",
       "1  [rt, berguna, berguna, telat, tahu, edan, sara...   \n",
       "2  [kadang, pikir, percaya, tuhan, jatuh, kali, k...   \n",
       "3        [berguna, berguna, saya, tahu, mata, sipit]   \n",
       "4  [berguna, berguna, kaum, cebong, kafir, dungu,...   \n",
       "5  [berguna, ya, bani, taplak, kawan, kawan, sang...   \n",
       "6  [deklarasi, pilih, kepala, daerah, aman, anti,...   \n",
       "7  [saya, selesai, re, watch, aldnoah, zero, kamp...   \n",
       "8  [admin, belanja, port, baik, nak, makan, ais, ...   \n",
       "9                             [berguna, enak, ngewe]   \n",
       "\n",
       "                                          stop_words  \\\n",
       "0  [cowok, usaha, lacak, perhati, , lantas, remeh...   \n",
       "1  [rt, berguna, berguna, telat, tahu, edan, sara...   \n",
       "2  [kadang, pikir, percaya, tuhan, jatuh, kali, k...   \n",
       "3            [berguna, berguna, , tahu, mata, sipit]   \n",
       "4  [berguna, berguna, kaum, cebong, kafir, dungu,...   \n",
       "5  [berguna, , bani, taplak, kawan, kawan, sangat...   \n",
       "6  [deklarasi, pilih, kepala, daerah, aman, anti,...   \n",
       "7  [, selesai, re, watch, aldnoah, zero, kampret,...   \n",
       "8  [admin, belanja, port, baik, nak, makan, ais, ...   \n",
       "9                             [berguna, enak, ngewe]   \n",
       "\n",
       "                                       stemmed_words  \\\n",
       "0  [cowok, usaha, lacak, perhati, , lantas, remeh...   \n",
       "1  [rt, guna, guna, telat, tahu, edan, sarap, , g...   \n",
       "2  [kadang, pikir, percaya, tuhan, jatuh, kali, k...   \n",
       "3                  [guna, guna, , tahu, mata, sipit]   \n",
       "4  [guna, guna, kaum, cebong, kafir, dungu, dungu...   \n",
       "5  [guna, , bani, taplak, kawan, kawan, sangat, s...   \n",
       "6  [deklarasi, pilih, kepala, daerah, aman, anti,...   \n",
       "7  [, selesai, re, watch, aldnoah, zero, kampret,...   \n",
       "8  [admin, belanja, port, baik, nak, makan, ais, ...   \n",
       "9                                [guna, enak, ngewe]   \n",
       "\n",
       "                                                Text  \n",
       "0  cowok usaha lacak perhati  lantas remeh perhat...  \n",
       "1  rt guna guna telat tahu edan sarap  gaul cigax...  \n",
       "2  kadang pikir percaya tuhan jatuh kali kali kad...  \n",
       "3                         guna guna  tahu mata sipit  \n",
       "4       guna guna kaum cebong kafir dungu dungu haha  \n",
       "5  guna  bani taplak kawan kawan sangat sangat sa...  \n",
       "6  deklarasi pilih kepala daerah aman anti hoaks ...  \n",
       "7   selesai re watch aldnoah zero kampret karakte...  \n",
       "8  admin belanja port baik nak makan ais kepal mi...  \n",
       "9                                    guna enak ngewe  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining Text\n",
    "df['Text'] = df['stemmed_words'].str.join(\" \")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "wFvYE3So3lky"
   },
   "outputs": [],
   "source": [
    "#melakukan ekstraksi fitur menggunakan tf-idf \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "vectorizer= TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['Text'])\n",
    "y=df['HS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    mantep banget deh\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(['mantep banget deh'],columns=['text'])['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwmOfwUA3uEj",
    "outputId": "1f3dfc11-b7ef-4647-9ec8-c12806b43bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (10535, 11445) (10535,) Test:  ((2634, 11445), (2634,))\n"
     ]
    }
   ],
   "source": [
    "#melakukan pembagian data training dan data testing yang mana data training 80% dqan data testing 20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,random_state=109)\n",
    "print(\"Train: \",X_train.shape,y_train.shape,\"Test: \",(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "H2HkpAtv32_s"
   },
   "outputs": [],
   "source": [
    "#pembuatan model menggunakan metode SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(random_state=0)\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dft1UEak38ON",
    "outputId": "4cb9cc0b-ae5c-4c22-8870-e1c80ff611ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix SVM\n",
      "[[1298  206]\n",
      " [ 282  848]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      1504\n",
      "           1       0.80      0.75      0.78      1130\n",
      "\n",
      "    accuracy                           0.81      2634\n",
      "   macro avg       0.81      0.81      0.81      2634\n",
      "weighted avg       0.81      0.81      0.81      2634\n",
      "\n",
      "AKURASI SVM: 0.815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(\"Confusion Matrix SVM\")\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "from sklearn.metrics import accuracy_score\n",
    "acu_svm=accuracy_score(y_test,y_pred)\n",
    "print('AKURASI SVM: %.3f' % acu_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "10W1QvWQ4AlP"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(svm, open('svm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qv0v7zX14e5P",
    "outputId": "baf8b7e9-11cb-4658-d6ba-b7e4b7831848",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Tree\n",
      "[[1217  287]\n",
      " [ 300  830]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1504\n",
      "           1       0.74      0.73      0.74      1130\n",
      "\n",
      "    accuracy                           0.78      2634\n",
      "   macro avg       0.77      0.77      0.77      2634\n",
      "weighted avg       0.78      0.78      0.78      2634\n",
      "\n",
      "AKURASI Tree: 0.777\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree = tree.DecisionTreeClassifier()\n",
    "tree.fit(X_train,y_train)\n",
    "y_pred=tree.predict(X_test)\n",
    "print(\"Confusion Matrix Tree\")\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "from sklearn.metrics import accuracy_score\n",
    "acu=accuracy_score(y_test,y_pred)\n",
    "print('AKURASI Tree: %.3f' % acu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUOoDlIi6ctp",
    "outputId": "bfc34f97-cd94-41aa-bdc9-62434268ff80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (10535, 11445) (10535,) Test:  ((2634, 11445), (2634,))\n",
      "Confusion Matrix nb\n",
      "[[678 826]\n",
      " [194 936]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.45      0.57      1504\n",
      "           1       0.53      0.83      0.65      1130\n",
      "\n",
      "    accuracy                           0.61      2634\n",
      "   macro avg       0.65      0.64      0.61      2634\n",
      "weighted avg       0.67      0.61      0.60      2634\n",
      "\n",
      "AKURASI nb: 0.613\n"
     ]
    }
   ],
   "source": [
    "X=X.toarray()\n",
    "#melakukan pembagian data training dan data testing yang mana data training 80% dqan data testing 20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,random_state=109)\n",
    "print(\"Train: \",X_train.shape,y_train.shape,\"Test: \",(X_test.shape,y_test.shape))\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train,y_train)\n",
    "y_pred=nb.predict(X_test)\n",
    "nb.fit(X_train,y_train)\n",
    "y_pred=nb.predict(X_test)\n",
    "print(\"Confusion Matrix nb\")\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "from sklearn.metrics import accuracy_score\n",
    "acu=accuracy_score(y_test,y_pred)\n",
    "print('AKURASI nb: %.3f' % acu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "KDFn8HkM6K5y"
   },
   "outputs": [],
   "source": [
    "moda = pickle.load(open('svm.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_file = 'vectorizer.pickle'\n",
    "pickle.dump(vectorizer, open(vec_file,  'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vectorizer.transform(['ya lu mau apa gue sikat lah'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aaa', 'aaaa', 'aaaaaaa', ..., 'zumi', 'zzzzzz', 'zzzzzzzz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11445)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2634, 11445)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moda.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
